{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Churn_Modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNhGtWXv9zxLd3M9iXi+r+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amit17133129/An-Explanation-To-Artificial-Neural-Network/blob/main/Churn_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt9hKtDimmmz"
      },
      "source": [
        "<h1><center>Explaination On Artificial Neural Netowrk</center></h1>\r\n",
        "<p align=\"center\">\r\n",
        "  <img src=\"https://github.com/amit17133129/codes/blob/master/Brain.gif?raw=true\" alt=\"Sublime's custom image\"/>\r\n",
        "</p>\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GShThPEomcwH"
      },
      "source": [
        "<center>An ANN is based on a collection of connected units or nodes called artificial neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal to other neurons. An artificial neuron that receives a signal then processes it and can signal neurons connected to it. The \"signal\" at a connection is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs. The connections are called edges. Neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Neurons may have a threshold such that a signal is sent only if the aggregate signal crosses that threshold. Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer), to the last layer (the output layer), possibly after traversing the layers multiple times.</center>\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI3GoO_ggoOr"
      },
      "source": [
        "## **Importing Pandas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x5ifkoymvgR"
      },
      "source": [
        "<center>Pandas is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series.</center>\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgK1b1ehmc_t"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4PuX8Wbg9ij"
      },
      "source": [
        "## **Importing Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS811L7Xm8bi"
      },
      "source": [
        "Here i have imported dataset of churn modelling in which you have features like 'RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\r\n",
        "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\r\n",
        "       'IsActiveMember', 'EstimatedSalary', 'Exited'. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "mobXuhMhm1h7",
        "outputId": "217bc603-540b-4541-f0e5-14b95775f78a"
      },
      "source": [
        "dataset = pd.read_csv(\"/content/Churn_Modelling.csv\")\r\n",
        "dataset"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9996</td>\n",
              "      <td>15606229</td>\n",
              "      <td>Obijiaku</td>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9997</td>\n",
              "      <td>15569892</td>\n",
              "      <td>Johnstone</td>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9998</td>\n",
              "      <td>15584532</td>\n",
              "      <td>Liu</td>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9999</td>\n",
              "      <td>15682355</td>\n",
              "      <td>Sabbatini</td>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>10000</td>\n",
              "      <td>15628319</td>\n",
              "      <td>Walker</td>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      RowNumber  CustomerId    Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0             1    15634602   Hargrave  ...               1       101348.88      1\n",
              "1             2    15647311       Hill  ...               1       112542.58      0\n",
              "2             3    15619304       Onio  ...               0       113931.57      1\n",
              "3             4    15701354       Boni  ...               0        93826.63      0\n",
              "4             5    15737888   Mitchell  ...               1        79084.10      0\n",
              "...         ...         ...        ...  ...             ...             ...    ...\n",
              "9995       9996    15606229   Obijiaku  ...               0        96270.64      0\n",
              "9996       9997    15569892  Johnstone  ...               1       101699.77      0\n",
              "9997       9998    15584532        Liu  ...               1        42085.58      1\n",
              "9998       9999    15682355  Sabbatini  ...               0        92888.52      1\n",
              "9999      10000    15628319     Walker  ...               0        38190.78      0\n",
              "\n",
              "[10000 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HLR4PIfm8mu",
        "outputId": "a516fdfd-2dfc-4bae-884b-e3b595893c37"
      },
      "source": [
        "dataset.columns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
              "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
              "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKddAiCmbpqq"
      },
      "source": [
        "As the *Exited* feature is to be in Y variable so below i am creating a y variable with *Exited* feature in that variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX_nMB5ym-pd"
      },
      "source": [
        "y = dataset['Exited']"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqpN6tGKcVA8"
      },
      "source": [
        "X will contains `['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\r\n",
        "                  'IsActiveMember', 'EstimatedSalary']` features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM5LKWpZoWyQ",
        "outputId": "6e2a6d0b-f019-4184-8307-766c4eac7e28"
      },
      "source": [
        "X = dataset[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\r\n",
        "                  'IsActiveMember', 'EstimatedSalary']]\r\n",
        "X.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k69l04yLhDN5"
      },
      "source": [
        "# **One Hot Encoding For Geography Feature**\r\n",
        "Here as you can see in the *Geography* reason you have you have three columns after one hot encoding i.e Germany, Spain, France. So to avoid dummy trap i have used a fn from pandas i.e `get_dummies` in which i have use  `drop_first=True` that will helps us to avoid dummy trap."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "_vIsIsvFnGVj",
        "outputId": "c0d18c74-848e-4f81-c7c5-84610f955688"
      },
      "source": [
        "Geo = pd.get_dummies(dataset['Geography'], drop_first=True)\r\n",
        "Geo"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Germany  Spain\n",
              "0           0      0\n",
              "1           0      1\n",
              "2           0      0\n",
              "3           0      0\n",
              "4           0      1\n",
              "...       ...    ...\n",
              "9995        0      0\n",
              "9996        0      0\n",
              "9997        0      0\n",
              "9998        1      0\n",
              "9999        0      0\n",
              "\n",
              "[10000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKy0zfZshNf-"
      },
      "source": [
        "## **One Hot Encoding For *Gender* Feature**\r\n",
        "Here as you can see in the Geography reason you have you have three columns after `one hot encoding` i.e Germany, Spain, France. So to avoid dummy trap i have used a fn from pandas i.e `get_dummies` in which i have use `drop_first=True` that will helps us to avoid dummy trap."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "ON9UNqn0nYCk",
        "outputId": "abfca29a-1230-4397-b5ca-be1d18595bdd"
      },
      "source": [
        "Gender = pd.get_dummies(dataset['Gender'], drop_first=True)\r\n",
        "Gender"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Male\n",
              "0        0\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0\n",
              "...    ...\n",
              "9995     1\n",
              "9996     1\n",
              "9997     0\n",
              "9998     1\n",
              "9999     0\n",
              "\n",
              "[10000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftfiVK3AhSWs"
      },
      "source": [
        "**Concatinating X, Geo, Gender**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZcUh06MneuH",
        "outputId": "956587e8-3981-40df-e0fb-bedc772b32e0"
      },
      "source": [
        "X = pd.concat([X, Geo, Gender], axis=1)\r\n",
        "X.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ7YYGeRhZVT"
      },
      "source": [
        "**importing *train_test_split***\r\n",
        "\r\n",
        "Before feeding your data into the neural network you need to split that data into `training set` and `testing set`. this can be done using \r\n",
        "\r\n",
        "```\r\n",
        "train_test_split method from sklearn library and from model_selection module\r\n",
        "```\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJIoiX_OseLl"
      },
      "source": [
        "\r\n",
        "\r\n",
        "<p align=\"center\">\r\n",
        "  <img src=\"https://github.com/amit17133129/codes/blob/master/train_test_split.gif?raw=true\" alt=\"Sublime's custom image\"/>\r\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqO6BORBn5ez"
      },
      "source": [
        "  from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=40)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLqAMG8cqdnL"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QH2XQKZhjii"
      },
      "source": [
        "## importing Sequrntial Model From keras "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6y6FfpCozhv"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "model = Sequential()            # creating Empty model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOKwRzkJh32L"
      },
      "source": [
        "#**Importing Dense Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRLGlsmSo8Ih"
      },
      "source": [
        "from keras.layers import Dense"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGLqGnH7h9rP"
      },
      "source": [
        "**Adding First Layer to model with neurons=8, input_feature=11 and activation fn = relu (rectified linear unit)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9jXryNIo-FU"
      },
      "source": [
        "model.add(Dense(units=8, activation='relu', input_dim=11))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV0gLjeHD9P_"
      },
      "source": [
        "`Relu`  is an activation function i.e its will activate the neurons in the hidden layers. The main functions of `relu` is that all the output from a layers from all the neuron will pass to another layers of the respective neurons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CgPHSrPmbLB"
      },
      "source": [
        "<p align=\"center\">\r\n",
        "  <img src=\"https://github.com/amit17133129/codes/blob/master/Relu.gif?raw=true\" alt=\"Sublime's custom image\"/>\r\n",
        "</p>\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHOGNKMkiQJX"
      },
      "source": [
        "## Adding Second Layer with neurons=6 and activation fn = relu  \r\n",
        "In this layer i have used `6 neurons` and with the `relu` activation fn.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMgmzznjpXgi"
      },
      "source": [
        "model.add(Dense(units=6, activation='relu'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv5AjBVujQDM"
      },
      "source": [
        "# Adding third layer with neurons=6 and activation fn = relu\r\n",
        "In this layer i have used `6 neurons` and with the `relu` activation fn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OppmvlA1pwJs"
      },
      "source": [
        "model.add(Dense(units=6, activation='relu'))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6eEHa0tjgDj"
      },
      "source": [
        "# Adding last layer with neurons=1 and activation fn = relu\r\n",
        "In this layer i have used `1 neuron` and with the `sigmoid` activation fn. As you can see in the below image after summation from all the neurons then the output goes to `sigmoid` fn and that fn will gives you a `binary` output (1/0). As it is giving onlu one output then only `one neuron` is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfbYCXm2F6-_"
      },
      "source": [
        "<p align=\"center\">\r\n",
        "  <img src=\"https://eecs.wsu.edu/~cook/dm/lectures/l5/img43.gif\" alt=\"Sublime's custom image\"/>\r\n",
        "</p>\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKgNLvCfp2q4"
      },
      "source": [
        "model.add(Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4mQS186qFDU",
        "outputId": "0193f445-f224-4b89-ceeb-4bc0db0d5b5b"
      },
      "source": [
        "model.get_config()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 11),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'dense_input',\n",
              "    'ragged': False,\n",
              "    'sparse': False}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'batch_input_shape': (None, 11),\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense',\n",
              "    'trainable': True,\n",
              "    'units': 8,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_1',\n",
              "    'trainable': True,\n",
              "    'units': 6,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_2',\n",
              "    'trainable': True,\n",
              "    'units': 6,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'sigmoid',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_3',\n",
              "    'trainable': True,\n",
              "    'units': 1,\n",
              "    'use_bias': True}}],\n",
              " 'name': 'sequential'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD4cJ0DjGuQy"
      },
      "source": [
        "## A  visaul Explaination of the Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRGZ772_lNEr"
      },
      "source": [
        "![DeeepLearning](https://github.com/amit17133129/codes/blob/master/Deep%20learning.gif?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuLJppWGqIPg",
        "outputId": "ee9704f2-613f-4c66-8544-19742f6417dd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 8)                 96        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 54        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 199\n",
            "Trainable params: 199\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orzdBCByAxkF"
      },
      "source": [
        "As you can see in below <b> `Optimizers Comaprision` </b> You will find that there are different tyes of optimizers are shown. In which they have different speed to move. This speed denotes the learning from the weights. if your optimizers have less speed then it will learn more things but as you can see in terms of <i> `Ada Delta` </i> the speed is quite high. So its jups and moves out of the graph. where as in case of <i>`Adam`</i> because i have used Adam you will find that speed of learning from the weights is quite slow compare to <i>`Ada Delta`</i>. Also you need to set the ```learning rate``` to move your optimizers very slowly. So, it can learn much more from the respective weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H0fWWdmAmTw"
      },
      "source": [
        "<p align=\"center\">\r\n",
        "  <img src=\"https://mlfromscratch.com/content/images/2019/12/saddle.gif\" alt=\"Sublime's custom image\"/>\r\n",
        "</p>\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j10mPq9Ha4t7"
      },
      "source": [
        "from keras.optimizers import Adam"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsXclF5VCAGS"
      },
      "source": [
        "As i have only one output that whether the Employee is exited from the company or not. i.e  Binary output (Exited/notexited). So the loss will be generating in binary. To handle the binary loss we have `binary_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unT3zQ3oaJf1"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.000001))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKhtyB_eHQ2k"
      },
      "source": [
        "<center><h1>Below You will find the weights of the model</h1></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FISTDIAJbGd-",
        "outputId": "42c8ddf6-3278-4060-cf67-2e4781ac3e08"
      },
      "source": [
        "model.get_weights()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.02066076, -0.28968173,  0.2522359 , -0.11069694, -0.30354032,\n",
              "         -0.35479504, -0.37940133,  0.12989408],\n",
              "        [ 0.40807408,  0.33400285, -0.29044044,  0.12279463,  0.02866024,\n",
              "          0.16505909, -0.43437654, -0.08052927],\n",
              "        [ 0.08574432,  0.31294584,  0.34127384, -0.5403073 ,  0.22737062,\n",
              "          0.3964677 , -0.4407091 , -0.11779466],\n",
              "        [-0.47511214, -0.51364213, -0.5219625 ,  0.08389795,  0.0482738 ,\n",
              "         -0.21094859, -0.04436564,  0.3212192 ],\n",
              "        [ 0.21555561, -0.07330978,  0.21048409,  0.51580375,  0.3181417 ,\n",
              "         -0.37364948,  0.38994366,  0.35384363],\n",
              "        [ 0.4174667 , -0.47016186, -0.18425742,  0.19694513, -0.42180163,\n",
              "         -0.0538637 ,  0.02123272,  0.3795498 ],\n",
              "        [-0.50346905,  0.22021902, -0.0587213 , -0.39206484, -0.11001834,\n",
              "          0.39269185, -0.01426095, -0.34227383],\n",
              "        [ 0.14976585,  0.4215495 , -0.4487199 , -0.10118306,  0.44541937,\n",
              "         -0.02592146, -0.3683002 , -0.15695423],\n",
              "        [ 0.04658729,  0.3677683 ,  0.50780183, -0.18169224, -0.40672716,\n",
              "         -0.27327177,  0.416915  ,  0.33695632],\n",
              "        [ 0.55054265, -0.0431208 ,  0.08847803, -0.4176634 ,  0.41596174,\n",
              "          0.06407928,  0.22342652,  0.4530285 ],\n",
              "        [-0.1881845 ,  0.55957144,  0.11970764, -0.53179413,  0.19073129,\n",
              "          0.4368927 , -0.16713011, -0.24164882]], dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
              " array([[-0.38369834, -0.45466506,  0.08300167,  0.6431782 , -0.137074  ,\n",
              "          0.62779343],\n",
              "        [-0.00921959, -0.05148399, -0.43598944, -0.47586703, -0.3992074 ,\n",
              "         -0.46359885],\n",
              "        [ 0.02408886, -0.4984544 ,  0.06853729, -0.09909028,  0.11974955,\n",
              "          0.47140014],\n",
              "        [-0.418697  , -0.11011851,  0.34275085,  0.45947206, -0.39859602,\n",
              "          0.00415146],\n",
              "        [-0.56797343, -0.41449997,  0.37440336, -0.2053113 , -0.51773435,\n",
              "          0.569739  ],\n",
              "        [ 0.41156614, -0.1457048 , -0.04102856,  0.2835266 ,  0.49666166,\n",
              "         -0.16993055],\n",
              "        [ 0.25853467,  0.01449186,  0.23077959, -0.44923282,  0.1784932 ,\n",
              "         -0.4885732 ],\n",
              "        [-0.18333298, -0.39147   ,  0.06050986, -0.21145234, -0.38709328,\n",
              "          0.0710482 ]], dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
              " array([[ 0.31347698,  0.2991895 ,  0.24508625,  0.2747    ,  0.58385545,\n",
              "          0.46211082],\n",
              "        [-0.45942527, -0.28549853, -0.4627154 ,  0.10429323,  0.35801822,\n",
              "         -0.4081499 ],\n",
              "        [-0.5215674 , -0.36142457, -0.2062847 ,  0.39537436,  0.61899203,\n",
              "         -0.57093555],\n",
              "        [-0.14456117,  0.17730016, -0.35279912,  0.23425555,  0.23910499,\n",
              "         -0.484769  ],\n",
              "        [ 0.24732089,  0.07750112,  0.2086935 ,  0.1879257 , -0.53177184,\n",
              "          0.12294507],\n",
              "        [ 0.45292348, -0.3549444 ,  0.19589955, -0.08474702, -0.20897552,\n",
              "         -0.52293193]], dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
              " array([[-0.29135615],\n",
              "        [-0.6119803 ],\n",
              "        [ 0.6753768 ],\n",
              "        [-0.05632192],\n",
              "        [ 0.12343192],\n",
              "        [ 0.11105609]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70RoiQBCHhMz"
      },
      "source": [
        "<center><h1>Training Phase</h1></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuRW3H0pHrNJ"
      },
      "source": [
        "For training the model we need to fit the model and it require training data i.e `X_train`, `y_train`. And the `epochs is 100`. That means your training data will goes 100 times through the neural network which you have build above with the respective layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pFed5M2MT_2"
      },
      "source": [
        "<p align=\"center\">\r\n",
        "  <img src=\"https://github.com/amit17133129/codes/blob/master/feedforward_backpropagation.gif?raw=true\" alt=\"Sublime's custom image\"/>\r\n",
        "</p>\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOBY-FSFbI0d",
        "outputId": "16513e09-8f02-4c0c-c443-df5c784d2df4"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 1ms/step - loss: 334.2865\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 998us/step - loss: 319.7225\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 970us/step - loss: 304.7026\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 967us/step - loss: 308.1894\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 987us/step - loss: 291.7599\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 288.4853\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 277.5352\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 268.2603\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 257.6669\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 247.9663\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 241.2878\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 992us/step - loss: 237.7679\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 223.5763\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 918us/step - loss: 212.1348\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 208.1311\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 968us/step - loss: 199.3574\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 192.1073\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 983us/step - loss: 179.5538\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 171.8051\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 162.6591\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 154.4323\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 147.5500\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 975us/step - loss: 133.3187\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 130.3280\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 123.2245\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 992us/step - loss: 114.9413\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 107.1242\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 99.9755\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 976us/step - loss: 92.6527\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 969us/step - loss: 84.3580\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 76.2165\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 72.1133\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 64.6858\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 59.2061\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 52.5562\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 48.6635\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 42.8801\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 38.8058\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 36.5574\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 33.0244\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 31.0097\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 32.4793\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 31.1288\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 991us/step - loss: 31.1337\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 28.5621\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 30.3988\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 29.6848\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 29.0631\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 28.3916\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 974us/step - loss: 28.3457\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 27.1065\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 27.6287\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 27.1368\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 27.1264\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 984us/step - loss: 25.3197\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 23.9523\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 23.1542\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 25.1388\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 23.1877\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 23.0455\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 23.2897\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 22.6371\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 21.1919\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 21.4505\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 21.0066\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 20.0127\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 19.9482\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 19.8167\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 997us/step - loss: 19.7622\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 19.0200\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 18.6084\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 17.1282\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 18.0116\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 17.9715\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 17.0897\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 16.8372\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 16.8302\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 16.5838\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 16.4868\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 15.5716\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 14.5191\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 14.1772\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 14.3615\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 13.8075\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 13.5754\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 13.4503\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 13.3970\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 12.4848\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 12.5361\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 11.9010\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 12.0105\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 11.4991\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 989us/step - loss: 10.9268\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 10.6491\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 10.7060\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 10.2463\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 979us/step - loss: 10.1727\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 10.1703\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 9.7232\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 9.7264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f03367dfe50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3S02wLRbY3h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "ad248f47-f8f1-44fa-8b44-4e83919e4fa3"
      },
      "source": [
        "loss = pd.DataFrame(model.history.history)\r\n",
        "loss"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>327.813019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>318.202637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>309.605621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>300.935791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>292.179413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>10.398937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>10.145731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>9.901025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>9.662745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>9.430536</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          loss\n",
              "0   327.813019\n",
              "1   318.202637\n",
              "2   309.605621\n",
              "3   300.935791\n",
              "4   292.179413\n",
              "..         ...\n",
              "95   10.398937\n",
              "96   10.145731\n",
              "97    9.901025\n",
              "98    9.662745\n",
              "99    9.430536\n",
              "\n",
              "[100 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKdLujgZMjlq"
      },
      "source": [
        "## Plotting Loss Graph\r\n",
        "As you can see the graph of the loss is slowly decreasing. So this can be possible because of `Adam` Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "GjvPQUXlbgio",
        "outputId": "97f38c27-cea4-48f6-e876-2172c4adb5a1"
      },
      "source": [
        "loss.plot()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0334101390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3EY9JiFOg3K"
      },
      "source": [
        "## Prediction\r\n",
        "To predict i am just giving random iputs but you can use the right values and it will predict on that case.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El7CxQkmbtzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ee4fb3-dfca-4bc8-864b-b2baab03d882"
      },
      "source": [
        "print(\"The employee will  :\", model.predict([[1,2,3,4,5,6,7,8,9,10,11]])[0][0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The employee will  : 0.4933369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu9hIlbXNSmc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}